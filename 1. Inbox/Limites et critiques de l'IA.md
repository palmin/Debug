## Confirmation des biais humains

Les techniques actuelles font que les réponses proposées par les IA faibles que nous maîtrisons sont aussi bonnes que les données d’entrée. Tay de Microsoft est  par exemple devenu raciste après 24h. 

## Peur de l'IA

La peur de l’IA s’enracine dans la question de savoir comment réagirait une intelligence supérieure à celle de l'homme ? On peut considéré cette forme d’intelligence supérieure prévisible étant donné l'accroissement des puissances de calcul et l'informatique quantique.

Elle est profondément ancré dans la culture populaire (Terminator par exemple).

La difficulté de compréhension des résultats est finalement avant tout une question de confiance.

## Limites éthiques et juridiques

Les responsabilités sont difficiles à établir. Quelle est la personnalité juridique d’un robot ?
Le licite ne se confond pas avec l’éthique : si l’on peut attendre une forme de légalité dans les réactions programmées de systèmes autonomes, il semble en revanche beaucoup plus délicat de les doter de la faculté d’apprécier une situation en fonction d’éléments d’ambiance et de traits de comportement. Voir [[Les robots de combat posent une question éthique]].

## Secteur privé

Le développement de l’IA se fait surtout par le secteur privé (voir [[Dualité public-privé dans le cyber]]), le contrôle est difficile et il ne paraît pas possible de garantir que les inventions seront utilisées au bénéfice de l’humanité.

## Augmentation des inégalités et adaptation à l’IA

Pour Laurent Alexandre, la différence d’accès à une utilisation efficace de l’IA (voir [[Quotien d'adaptation à l'IA]]) va creuser les inégalités.